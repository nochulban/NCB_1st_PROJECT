import boto3
import os
import connectDatabase
import hashlib
from dotenv import load_dotenv

os.chdir(os.path.dirname(os.path.abspath(__file__))) #ê²½ë¡œ ìµœì†Œí™” ì‹œ í•„ìš”

# .env íŒŒì¼ ë¡œë“œ (AWS ìê²© ì¦ëª… ë¶ˆëŸ¬ì˜¤ê¸°)
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìê²© ì¦ëª… ê°€ì ¸ì˜¤ê¸°
# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3 = boto3.client(
    's3',
    aws_access_key_id = os.getenv("AWS_ACCESS_KEY_ID"),
    aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
    region_name=os.getenv("REGION_NAME")
)

# ğŸª£ ë²„í‚· ì´ë¦„: https://jaeyoon-example.s3-ap-northeast-2.amazonaws.com/

#bucket_name = bucket_url.split('//')[1].split('/')[0].split('.')[0]
#bucket_name = 'jaeyoon-example'
#bucket_name = 'photoism-apse-cms-prd'

# ğŸ“ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¶ì€ í´ë” (S3 ë‚´ ê²½ë¡œ)
prefix = ''  # ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•˜ë©´ ë²„í‚· ì „ì²´ì—ì„œ ê°ì²´ë¥¼ ë‚˜ì—´í•¨
#prefix = 'example/'  # 'example/' ì•ˆì— ìˆëŠ” ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ

# ğŸ’¾ ë¡œì»¬ì— ì €ì¥í•  ë””ë ‰í† ë¦¬
# linux ë²„ì „ìœ¼ë¡œ ë³€ê²½í•´ì•¼í•¨
local_download_root = '/opt/test'  # ì›í•˜ëŠ” ë¡œì»¬ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”
#local_download_root = 'D:\Code'  # ì›í•˜ëŠ” ë¡œì»¬ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”

# S3ì—ì„œ í•´ë‹¹ prefix ì•„ë˜ì˜ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
def dataDownload(url, bucket_name):
    paginator = s3.get_paginator('list_objects_v2')
    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):
        for obj in page.get('Contents', []):
            key = obj['Key']
            if key.endswith('/'):  # ë””ë ‰í„°ë¦¬ë¼ë©´ ìƒëµ
                continue

            # ë¡œì»¬ ì €ì¥ ê²½ë¡œ êµ¬ì„±
            local_path = os.path.join(local_download_root, key)
            os.makedirs(os.path.dirname(local_path), exist_ok=True)

            print(f'Downloading s3://{bucket_name}/{key} -> {local_path}')
            s3.download_file(bucket_name, key, local_path)
            fileHash = get_file_hash(local_path)
            connectDatabase.updateFileHash(url, fileHash)

    print(f"âœ… All files downloaded from bucket: {bucket_name}")

def get_file_hash(file_path):
    sha256_hash = hashlib.sha256()
    with open(file_path, 'rb') as f:
        for byte_block in iter(lambda: f.read(4096), b''):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


def main():
    bucket_urls =connectDatabase.getDistinctBucketUrl()
    for url_tuple in bucket_urls:
        url = url_tuple[0]
        bucket_name = url.split('//')[1].split('/')[0].split('.')[0]
        if bucket_name:
            print(f"ğŸ“¦ Processing bucket: {bucket_name}")
            dataDownload(url, bucket_name)
            
        else:
            print(f"âŒ Invalid bucket URL: {url}")
